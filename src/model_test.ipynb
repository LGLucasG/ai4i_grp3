{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size:int, output_size:int, hidden_size:int, n_layers:int):\n",
    "        \"\"\"\n",
    "        Inizalization of the MLP model.\n",
    "\n",
    "        Args:\n",
    "            input_size (int): Input features (last dimensión of the imput data)\n",
    "            output_size (int): Output features (last dimensión of the output data)\n",
    "            hidden_size (int): Number of neurons in the hidding layer (recommended, no more than 128)\n",
    "            layers (int): Number of layers \n",
    "        \"\"\"\n",
    "        super(MLP, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.layers_list = nn.ModuleList()\n",
    "\n",
    "        for layer in range(n_layers):\n",
    "            if layer == 0:\n",
    "                self.layers_list.append(nn.Linear(input_size, hidden_size))\n",
    "            elif layer == n_layers -1:\n",
    "                self.layers_list.append(nn.Linear(hidden_size, output_size))\n",
    "            else:\n",
    "                self.layers_list.append(nn.Linear(hidden_size, hidden_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        out = x\n",
    "        for layer in self.layers_list:\n",
    "            out = layer(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "PytorchStreamReader failed locating file constants.pkl: file not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m loaded_model \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMLP_model.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/jit/_serialization.py:162\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, _extra_files, _restore_shapes)\u001b[0m\n\u001b[1;32m    160\u001b[0m cu \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39mCompilationUnit()\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, (\u001b[38;5;28mstr\u001b[39m, pathlib\u001b[38;5;241m.\u001b[39mPath)):\n\u001b[0;32m--> 162\u001b[0m     cpp_module \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_ir_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_extra_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_restore_shapes\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    164\u001b[0m     cpp_module \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39mimport_ir_module_from_buffer(\n\u001b[1;32m    165\u001b[0m         cu, f\u001b[38;5;241m.\u001b[39mread(), map_location, _extra_files, _restore_shapes\n\u001b[1;32m    166\u001b[0m     )  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: PytorchStreamReader failed locating file constants.pkl: file not found"
     ]
    }
   ],
   "source": [
    "loaded_model = torch.load(\"MLP_model.pt\")\n",
    "modelo = M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4253/1907171907.py:6: RuntimeWarning: invalid value encountered in divide\n",
      "  X_scaled = ((X - X.mean(axis=0)) / X.std(axis=0))\n"
     ]
    }
   ],
   "source": [
    "#Load data\n",
    "X = pd.read_csv(\"R11_entrada_anterior.csv\").to_numpy() #sensors\n",
    "y = pd.read_csv('R11_salida.csv').to_numpy() #position\n",
    "\n",
    "#Normalize data\n",
    "X_scaled = ((X - X.mean(axis=0)) / X.std(axis=0))\n",
    "X_scaled = X_scaled[:, ~np.isnan(X_scaled).any(axis=0)]\n",
    "y_scaled = (y - y.mean(axis=0)) / y.std(axis=0)\n",
    "y_scaled = y_scaled[:, ~np.isnan(y_scaled).any(axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert into tensor\n",
    "X = torch.tensor(X_scaled, dtype=torch.float32)\n",
    "y = torch.tensor(y_scaled, dtype=torch.float32)\n",
    "\n",
    "#Create pythorch class\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X, self.y = X, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.X[i], self.y[i]\n",
    "\n",
    "#Initialize pytorch class\n",
    "train_dataset = TimeSeriesDataset(X, y)\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'collections.OrderedDict' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mloaded_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'collections.OrderedDict' object is not callable"
     ]
    }
   ],
   "source": [
    "loaded_model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('layers_list.0.weight',\n",
       "              tensor([[ 4.2570e-01, -9.2440e-02,  7.1098e-02,  ...,  2.3045e-01,\n",
       "                       -6.7970e-02, -1.6678e-01],\n",
       "                      [-2.8336e-01,  1.4804e-01, -4.1101e-02,  ..., -1.6434e-01,\n",
       "                        7.7184e-02, -2.6636e-01],\n",
       "                      [-1.2107e-01,  4.6695e-02, -7.1514e-02,  ...,  1.0512e-01,\n",
       "                        1.2342e-01, -5.5740e-02],\n",
       "                      ...,\n",
       "                      [ 1.5867e-04, -5.6262e-02, -9.4308e-02,  ...,  1.5625e-01,\n",
       "                        5.5670e-02, -2.9439e-01],\n",
       "                      [ 1.5680e-01, -1.9915e-01, -1.1384e-01,  ..., -1.1571e-01,\n",
       "                       -1.3283e-01, -2.9581e-01],\n",
       "                      [ 7.9594e-02, -1.2219e-01,  1.3072e-01,  ...,  9.0397e-02,\n",
       "                        1.5624e-02,  4.1595e-02]])),\n",
       "             ('layers_list.0.bias',\n",
       "              tensor([-0.1441,  0.1139, -0.0116,  0.1222, -0.0076, -0.1088, -0.0009,  0.0551,\n",
       "                       0.1052, -0.0992,  0.0922,  0.0059, -0.0613,  0.0699, -0.1120, -0.0652,\n",
       "                      -0.0505, -0.0128, -0.0606, -0.0984,  0.0223, -0.0992,  0.1115, -0.1387,\n",
       "                       0.0392, -0.0796,  0.1169,  0.1094,  0.0198, -0.1470,  0.1190, -0.0528])),\n",
       "             ('layers_list.1.weight',\n",
       "              tensor([[-0.0803,  0.2143, -0.1504,  ..., -0.0227,  0.0081,  0.1140],\n",
       "                      [-0.1588, -0.0450,  0.0464,  ...,  0.0816,  0.1128,  0.1518],\n",
       "                      [ 0.3900, -0.1365,  0.1234,  ...,  0.1453,  0.0727, -0.1396],\n",
       "                      ...,\n",
       "                      [-0.0562,  0.1598,  0.1152,  ...,  0.3099, -0.0840,  0.1324],\n",
       "                      [ 0.1474, -0.1441,  0.0079,  ...,  0.0896,  0.1572, -0.1315],\n",
       "                      [ 0.0675,  0.0747, -0.1703,  ..., -0.1461,  0.0305,  0.1942]])),\n",
       "             ('layers_list.1.bias',\n",
       "              tensor([-0.0008,  0.0154,  0.0808, -0.0207, -0.1064, -0.1513, -0.0332,  0.0617,\n",
       "                      -0.1127,  0.1466,  0.0212,  0.1637,  0.0956,  0.0223,  0.0651, -0.0975,\n",
       "                       0.0685,  0.0067,  0.0405, -0.1221, -0.1345,  0.1659, -0.0408,  0.0138,\n",
       "                       0.0256,  0.0565,  0.1917,  0.0322,  0.0378, -0.0766,  0.0931,  0.0321])),\n",
       "             ('layers_list.2.weight',\n",
       "              tensor([[-0.1588, -0.1385, -0.0422,  ..., -0.0052, -0.0775,  0.0759],\n",
       "                      [ 0.1201, -0.1529,  0.1673,  ..., -0.0691,  0.1517, -0.0916],\n",
       "                      [ 0.2351,  0.0967, -0.0925,  ...,  0.1614, -0.1587,  0.1225],\n",
       "                      ...,\n",
       "                      [ 0.1768, -0.1729,  0.1274,  ...,  0.2233, -0.0499,  0.1242],\n",
       "                      [ 0.1427, -0.0502,  0.0159,  ...,  0.1667,  0.1190, -0.1597],\n",
       "                      [ 0.0794, -0.0007, -0.0588,  ..., -0.1252, -0.0790, -0.0241]])),\n",
       "             ('layers_list.2.bias',\n",
       "              tensor([-0.0917,  0.0340,  0.0677,  0.0741,  0.1439, -0.0571, -0.0752,  0.1028,\n",
       "                      -0.0473, -0.0591,  0.1140,  0.0909,  0.1124, -0.0919,  0.0310,  0.0654,\n",
       "                      -0.1512, -0.0781, -0.1189, -0.1448, -0.0281,  0.1997, -0.0681, -0.0811,\n",
       "                       0.0596, -0.0019,  0.1254,  0.0265,  0.0386,  0.0469,  0.1293, -0.0528])),\n",
       "             ('layers_list.3.weight',\n",
       "              tensor([[-0.1043,  0.0145, -0.2015,  0.1894,  0.1845,  0.0330,  0.1763, -0.0488,\n",
       "                       -0.0665, -0.2061,  0.0687, -0.1576,  0.1921,  0.1254, -0.0043,  0.1695,\n",
       "                        0.0024, -0.2596, -0.1486, -0.0574,  0.2827, -0.1349, -0.1464, -0.0817,\n",
       "                       -0.1871, -0.3266,  0.1259,  0.1736,  0.1338,  0.1386, -0.0601, -0.0483],\n",
       "                      [ 0.2102, -0.2012,  0.1860,  0.1811, -0.3095, -0.0049, -0.0010,  0.3137,\n",
       "                       -0.1823, -0.0579, -0.2593, -0.2608, -0.2079, -0.3263, -0.0715, -0.0664,\n",
       "                        0.0381, -0.2297,  0.1360,  0.0610,  0.3141,  0.2159,  0.0066, -0.0617,\n",
       "                       -0.1249,  0.0975,  0.0892,  0.0745, -0.2389,  0.0398, -0.1862,  0.1374],\n",
       "                      [-0.1031,  0.3037, -0.1522, -0.2215, -0.1651, -0.1529, -0.2537,  0.1590,\n",
       "                       -0.1016,  0.0058,  0.0942,  0.0585, -0.0569,  0.0371,  0.1222, -0.2178,\n",
       "                       -0.2238, -0.3718,  0.0308,  0.1510, -0.2026, -0.0900, -0.0620,  0.2194,\n",
       "                        0.1160, -0.1653,  0.1242, -0.2397, -0.0531,  0.2545,  0.0309,  0.0742],\n",
       "                      [-0.0039,  0.1294,  0.0169, -0.0393,  0.0435, -0.0252,  0.1270, -0.1425,\n",
       "                        0.0628,  0.0139, -0.1530, -0.0883, -0.1316,  0.0454, -0.0985,  0.1788,\n",
       "                        0.1344,  0.0559,  0.1133,  0.0223,  0.2005, -0.2234, -0.1417,  0.0841,\n",
       "                       -0.0310,  0.0696, -0.1635, -0.2768, -0.2724,  0.1062,  0.0647, -0.0414],\n",
       "                      [-0.1677,  0.0853,  0.0761, -0.1775,  0.1126,  0.0392, -0.1186,  0.1086,\n",
       "                       -0.0463,  0.0332, -0.1129, -0.0354,  0.1030,  0.1772, -0.0798,  0.0493,\n",
       "                        0.0696, -0.0081,  0.1044,  0.1297,  0.2336,  0.1228, -0.1276, -0.0605,\n",
       "                       -0.1657,  0.2344,  0.1282,  0.1280, -0.0295, -0.0067,  0.2442,  0.0343],\n",
       "                      [ 0.0304,  0.0831, -0.0054,  0.1152, -0.1542,  0.1770, -0.1412, -0.0565,\n",
       "                       -0.0534, -0.0326,  0.1479,  0.0700,  0.0432, -0.0334,  0.1726,  0.1962,\n",
       "                        0.1269, -0.0928,  0.1571, -0.1048,  0.0612,  0.0776,  0.1434,  0.0894,\n",
       "                       -0.0099,  0.0159,  0.0959,  0.0880,  0.1071, -0.0506,  0.0551, -0.2060],\n",
       "                      [ 0.1852, -0.0443, -0.0407,  0.1158, -0.1758, -0.0041, -0.0589, -0.0980,\n",
       "                        0.2445,  0.0563, -0.0743,  0.0836, -0.0846,  0.1501,  0.2701, -0.0567,\n",
       "                        0.1145, -0.0568, -0.2614,  0.2953,  0.1894,  0.0447, -0.1090,  0.0097,\n",
       "                        0.0637,  0.1422, -0.2113, -0.0071,  0.0437, -0.0110, -0.0831,  0.0481],\n",
       "                      [-0.0331,  0.1150, -0.2926,  0.1728, -0.1643, -0.2895, -0.0968, -0.1514,\n",
       "                       -0.2965, -0.0016, -0.2024, -0.0293, -0.1203, -0.1433,  0.0413,  0.0422,\n",
       "                        0.1617,  0.0742,  0.0524,  0.0471,  0.0847, -0.0681, -0.2829,  0.0741,\n",
       "                       -0.0909,  0.1006, -0.1573,  0.0894,  0.2544, -0.1690, -0.1397, -0.0385],\n",
       "                      [ 0.1134,  0.0293, -0.1866, -0.1062, -0.0869, -0.0970,  0.1791,  0.2773,\n",
       "                       -0.0201,  0.2075, -0.0392,  0.1410, -0.0544, -0.0533, -0.0181,  0.0683,\n",
       "                       -0.2741,  0.1644, -0.1020,  0.1100,  0.0259, -0.2154,  0.2183,  0.0827,\n",
       "                        0.0349,  0.1296, -0.1763,  0.1805,  0.1940,  0.2919,  0.1502,  0.0042],\n",
       "                      [-0.1580, -0.0446,  0.1537, -0.0274, -0.0517,  0.1512, -0.0971, -0.0253,\n",
       "                        0.0991,  0.1180, -0.1015,  0.0629, -0.0810, -0.0207, -0.1963,  0.0007,\n",
       "                       -0.0963,  0.0150,  0.1619,  0.1764,  0.1426,  0.0558, -0.1920, -0.0922,\n",
       "                        0.1498, -0.1556, -0.0932, -0.0034,  0.1944,  0.0401, -0.0549, -0.0953],\n",
       "                      [-0.1353,  0.2039,  0.2361,  0.2578,  0.0033, -0.2092,  0.1425, -0.0865,\n",
       "                        0.1061, -0.2147, -0.0774,  0.2492,  0.2569, -0.2088,  0.0974, -0.2914,\n",
       "                        0.2245, -0.1875,  0.3038, -0.1155,  0.1393, -0.1877,  0.2563, -0.0534,\n",
       "                        0.0834,  0.1507, -0.1118,  0.1074,  0.1128,  0.1266,  0.1646,  0.1551]])),\n",
       "             ('layers_list.3.bias',\n",
       "              tensor([ 0.1058, -0.0097,  0.0118,  0.1203, -0.1164, -0.1175, -0.1106, -0.1391,\n",
       "                       0.0456,  0.0178, -0.0942]))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
